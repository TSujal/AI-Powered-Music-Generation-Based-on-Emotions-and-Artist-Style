{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "ooZNjksQ4RF8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRFJSUoY4RCa",
        "outputId": "1495a243-cdb1-4ec2-c484-6f39127e6f07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.11.4-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.11.4-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_youtube(song_name, singer_name):\n",
        "    \"\"\"\n",
        "    Searches YouTube for a song by name and singer, and returns the URL of the top result.\n",
        "\n",
        "    Parameters:\n",
        "    - song_name (str): The name of the song.\n",
        "    - singer_name (str): The name of the singer.\n",
        "\n",
        "    Returns:\n",
        "    - str: The URL of the top YouTube search result.\n",
        "    \"\"\"\n",
        "    query = f\"{song_name} {singer_name}\"\n",
        "    command = f'yt-dlp \"ytsearch:{query}\" --get-id --skip-download'\n",
        "\n",
        "    try:\n",
        "        # Execute the search and retrieve video ID\n",
        "        video_id = subprocess.check_output(command, shell=True, text=True).strip()\n",
        "        youtube_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "        return youtube_url\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error occurred during YouTube search: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wiXGYb8A4PfO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dLbBw6PGuWin"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def download_youtube_audio(df_songs, output_folder, audio_format=\"mp3\"):\n",
        "    \"\"\"\n",
        "    Download audio from YouTube videos using URLs from a DataFrame and save them to a specified folder.\n",
        "\n",
        "    Parameters:\n",
        "    - df_songs (pd.DataFrame): DataFrame containing songs and their corresponding URLs.\n",
        "    - output_folder (str): The folder where the audio files will be saved.\n",
        "    - audio_format (str): The audio format for the output files (default is 'mp3').\n",
        "    \"\"\"\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Check if the 'url' column is present in the DataFrame\n",
        "    if 'url' not in df_songs.columns:\n",
        "        print(\"The 'url' column is missing from the dataset.\")\n",
        "        return\n",
        "\n",
        "    youtube_pattern = re.compile(r'(https?://)?(www\\.)?(youtube\\.com/watch\\?v=|youtu\\.be/)([a-zA-Z0-9_-]{11})')\n",
        "    audio_counter = 1  # Initialize the audio file counter\n",
        "\n",
        "    for index, row in df_songs.iterrows():\n",
        "        url = row[\"url\"].strip()\n",
        "        song_title = row[\"Song\"].strip().replace('/', '-')  # Replace any slashes to avoid path issues\n",
        "\n",
        "        if youtube_pattern.match(url):\n",
        "            # Create the command to fetch audio\n",
        "            audio_file_path = f\"{output_folder}/{audio_counter}.{song_title}.{audio_format}\"\n",
        "            command = f'yt-dlp -x --audio-format {audio_format} -o \"{audio_file_path}\" \"{url}\"'\n",
        "            try:\n",
        "                subprocess.run(command, shell=True, check=True)\n",
        "                print(f\"[{audio_counter}] Audio fetched successfully: {song_title} - {url}\")\n",
        "                audio_counter += 1  # Increment counter only for successful fetch\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"[{audio_counter}] No audio fetched for: {song_title} - {url} - Error: {e}\")\n",
        "                # Do not increment audio_counter if fetch fails\n",
        "        else:\n",
        "            print(f\"[{audio_counter}] No audio fetched for: {song_title} - {url} - Invalid URL\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "\n",
        "def play_audio(file_path_or_url):\n",
        "    \"\"\"\n",
        "    Play an MP3 audio file from a local path or a URL.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path_or_url (str): Path to the MP3 file or a URL of the audio file.\n",
        "    \"\"\"\n",
        "    # Check if the provided path is a local file and exists\n",
        "    if os.path.isfile(file_path_or_url):\n",
        "        print(f\"Playing local file: {file_path_or_url}\")\n",
        "    else:\n",
        "        print(f\"Playing audio from URL: {file_path_or_url}\")\n",
        "\n",
        "    # Load and play the audio file\n",
        "    audio = Audio(file_path_or_url, autoplay=True)\n",
        "    display(audio)"
      ],
      "metadata": {
        "id": "i-tOVFmWwL4N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "\n",
        "def get_top_song_emotions_for_dataset(df, emotion_keywords):\n",
        "    \"\"\"\n",
        "    This function fetches a minimum of 1 and a maximum of 2 emotions per song based on keywords\n",
        "    found in the song's Wikipedia page. If less than 1 emotion is found, it will fill with 'NO EMOTION'.\n",
        "    If the page is not found, 'Page not found' will be set.\n",
        "    \"\"\"\n",
        "    for index, row in df.iterrows():\n",
        "        song_name = row['Song']  # Assumes there is a 'Song' column\n",
        "        query = song_name.replace(\" \", \"_\")\n",
        "        url = f\"https://en.wikipedia.org/wiki/{query}\"\n",
        "\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "            paragraphs = soup.find_all(\"p\")\n",
        "\n",
        "            # Counter to store detected emotions and their frequency\n",
        "            emotion_counter = Counter()\n",
        "\n",
        "            # Process each paragraph to detect emotions\n",
        "            for paragraph in paragraphs:\n",
        "                text = paragraph.get_text().lower()  # Convert text to lowercase\n",
        "                for keyword in emotion_keywords:\n",
        "                    if keyword in text:\n",
        "                        emotion_counter[keyword.capitalize()] += 1  # Count occurrences of each emotion\n",
        "\n",
        "            # Select the top 2 emotions based on frequency (if available)\n",
        "            top_emotions = [emotion for emotion, count in emotion_counter.most_common(2)]\n",
        "\n",
        "            # Handle the case where no emotions were found\n",
        "            if len(top_emotions) == 0:\n",
        "                df.at[index, 'Emotion'] = \"NO EMOTION\"\n",
        "            else:\n",
        "                # If there's only one emotion, leave it as it is, else join top 2\n",
        "                df.at[index, 'Emotion'] = ', '.join(top_emotions)\n",
        "        else:\n",
        "            # In case the Wikipedia page is not found\n",
        "            df.at[index, 'Emotion'] = \"Page not found\"\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "6EqxOqaB4Cp6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "metadata": {
        "id": "kfSBgLyB4kkw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting numeric features from the audio mp3 file:\n",
        "# Function to extract audio features\n",
        "def extract_audio_features(file_path, n_fft=1024, hop_length=256):\n",
        "    y, sr = librosa.load(file_path, sr=None)  # Load audio with original sampling rate\n",
        "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
        "    magnitude, _ = librosa.magphase(D)\n",
        "    original_length = len(y)\n",
        "    feature_vector = magnitude.flatten()  # Flatten to a 1D array\n",
        "    return feature_vector, sr, original_length\n"
      ],
      "metadata": {
        "id": "nVNPWdMqAqbt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "def reconstruct_audio_from_features(feature_vector, sr, original_length, output_path, n_fft=512, hop_length=256, n_iter=32):\n",
        "    # Reshape the feature vector back to the 2D spectrogram format\n",
        "    num_freq_bins = n_fft // 2 + 1\n",
        "    magnitude = feature_vector.reshape((num_freq_bins, -1))\n",
        "\n",
        "    # Use Griffin-Lim to reconstruct the audio from the magnitude spectrogram\n",
        "    audio_reconstructed = librosa.griffinlim(magnitude, hop_length=hop_length, n_iter=n_iter)\n",
        "\n",
        "    # Adjust the length of the reconstructed audio to match the original\n",
        "    audio_reconstructed = pad_or_trim_audio(audio_reconstructed, original_length)\n",
        "\n",
        "    # Save the reconstructed audio as a .wav file\n",
        "    sf.write(output_path, audio_reconstructed, sr)\n",
        "    print(f\"Reconstructed audio saved as {output_path}\")"
      ],
      "metadata": {
        "id": "TPjf13QtA2D1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_or_trim_audio(audio, original_length):\n",
        "    if len(audio) < original_length:\n",
        "        # Pad with zeros if the reconstructed audio is shorter\n",
        "        padding_length = original_length - len(audio)\n",
        "        audio = np.pad(audio, (0, padding_length), 'constant')\n",
        "    else:\n",
        "        # Trim the audio if it's longer than the original length\n",
        "        audio = audio[:original_length]\n",
        "    return audio"
      ],
      "metadata": {
        "id": "1NGEojo9qsy0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Um9gKHR2qtej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
